{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0b94a26-9e7a-4040-9a1d-7a475a648010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lr_utils import load_dataset\n",
    "import h5py\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48c5f15-77c3-4112-a030-0b3cd9b09d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, Y):\n",
    "    m = X.shape[1]\n",
    "    permutation = np.random.permutation(m)\n",
    "    X_shuffled = X[:, permutation]\n",
    "    Y_shuffled = Y[:, permutation]\n",
    "    return X_shuffled, Y_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fc0986-5ec6-49a8-a8e4-802b18679869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batches(X, batch_size=64):\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "    num_full_batches = m // batch_size\n",
    "\n",
    "    for k in range(num_full_batches):\n",
    "        mini_batch = X[:, k * batch_size : (k + 1) * batch_size]\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    if m % batch_size != 0:\n",
    "        mini_batch = X[:, num_full_batches * batch_size :]\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbc2328-01db-417d-b303-3f677f3b6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 209)\n",
      "(12288, 64)\n"
     ]
    }
   ],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()\n",
    "train_set_x = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "test_set_x = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "train_set_x = train_set_x/255.\n",
    "test_set_x = test_set_x/255.\n",
    "train_set_x_shuffled, train_set_y_shuffeled = shuffle_data(train_set_x, train_set_y)\n",
    "print(train_set_x_shuffled.shape)\n",
    "train_x_mini = create_mini_batches(train_set_x_shuffled)\n",
    "train_y_mini = create_mini_batches(train_set_y_shuffeled)\n",
    "print(train_x_mini[0].shape)\n",
    "#print(train_x_mini[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61980954-a786-4148-b4b7-4a7da9040b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    a = 1/ (1+ np.exp(-z))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69185e53-366b-48a4-8aab-828b07226e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RELU(z):\n",
    "    a = np.maximum(0, z)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ecda8b-5618-47ca-b2be-e86e8d608a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    a = np.tanh(z)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62da26c6-ca0a-4b98-84ad-94cc365a85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_zero(dimensions):\n",
    "    layers = dimensions.shape[0]\n",
    "    B = np.empty((layers, 1), dtype=object)\n",
    "\n",
    "    for l in range(layers):\n",
    "        b = np.zeros((dimensions[l][0], 1))\n",
    "        B[l, 0] = b\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d08cb1b0-d614-4cc4-af9b-caf5be365e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_random(dimensions):\n",
    "    layers = dimensions.shape[0]\n",
    "    W = np.empty((layers, 1), dtype=object)\n",
    "    for l in range(layers):\n",
    "        w = np.random.rand(dimensions[l][1], dimensions[l][0])\n",
    "        W[l,0] = w\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d40ab23-ebe9-4e4d-8042-77f1c87f1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HE_initialize(dimensions):\n",
    "    layers = dimensions.shape[0]\n",
    "    W = np.empty((layers, 1), dtype=object)\n",
    "    for l in range(layers):\n",
    "        #print(dimensions[l][1])\n",
    "        w = np.random.rand(dimensions[l][1], dimensions[l][0])* np.sqrt(2 /dimensions[l][1])\n",
    "        W[l,0] = w\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "498fa17b-738f-48dc-bde5-11b0505b1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(W, X, B):\n",
    "    layers = W.shape[0]\n",
    "    A = np.empty((layers+ 1, 1), dtype=object)\n",
    "    A[0][0] = X\n",
    "    for l in range(layers):\n",
    "        z = np.dot(W[l][0].T, A[l][0]) + B[l][0]\n",
    "        if l != layers-1:\n",
    "            a = RELU(z)\n",
    "        else:\n",
    "            a = sigmoid(z)\n",
    "        A[l+1,0] = a\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b935b6-6980-4e26-bb50-5d1c16d43e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(W, B, A, Y, use_L2 = False, lambd = 0.1):\n",
    "    m = Y.shape[1]\n",
    "    L = W.shape[0] \n",
    "    dW = np.empty_like(W)\n",
    "    dB = np.empty_like(B)\n",
    "    dZ = None\n",
    "\n",
    "    A_final = A[L, 0]  # A[4]\n",
    "    dZ = A_final - Y  # sigmoid derivative for BCE\n",
    "    if use_L2 == True:\n",
    "        dW[L-1, 0] = np.dot(A[L-1, 0], dZ.T) / m + (lambd / m) * W[L-1, 0]\n",
    "    else:\n",
    "        dW[L-1, 0] = np.dot(A[L-1, 0], dZ.T) / m  # A3 * dZ4.T\n",
    "    dB[L-1, 0] = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "\n",
    "    for l in reversed(range(L - 1)):\n",
    "        Z = np.dot(W[l, 0].T, A[l, 0]) + B[l, 0]  # recompute Z[l+1]\n",
    "        dA = np.dot(W[l + 1, 0], dZ)  # backprop through W\n",
    "        dZ = dA * (Z > 0)  # ReLU derivative\n",
    "        if use_L2 == True:\n",
    "            dW[l, 0] = np.dot(A[l, 0], dZ.T) / m + (lambd / m) * W[l, 0]\n",
    "        else:\n",
    "            dW[l, 0] = np.dot(A[l, 0], dZ.T) / m\n",
    "        dB[l, 0] = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "\n",
    "    return dW, dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd1a1a0-4ee7-4745-a859-ba09f5b6a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(Y, A, use_L2 = False, lambd = 0.1):\n",
    "    m = Y.shape[1]\n",
    "    cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
    "    if use_L2 == True:\n",
    "        L2_cost = 0\n",
    "        for l in range(W.shape[0]):\n",
    "            L2_cost += np.sum(np.square(W[l, 0]))\n",
    "        L2_cost *= lambd / (2 * m)\n",
    "        return cost + L2_cost\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e12db18e-8ebc-4ade-8ab9-ba6ee0c070bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perdiction(Z):\n",
    "    for i in range(Z.shape[1]):\n",
    "        if Z[0][i] > 0.5:\n",
    "            Z[0][i] = 1\n",
    "        else:\n",
    "            Z[0][i] = 0\n",
    "    return Z\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a48841-1823-4076-84e5-448de95ba9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer():\n",
    "    Layers = int(input(\"input number of layers: \"))\n",
    "    neurons = []\n",
    "    for i in range(Layers):\n",
    "        neurons.append(int(input(\"input nerouns for \" + str(i+1) + \"th layer: \")))\n",
    "    dim = []\n",
    "    for i in range(Layers):\n",
    "        if i == 0:\n",
    "            dim.append([neurons[0], 12288])\n",
    "        else:\n",
    "            dim.append([neurons[i], neurons[i-1]])\n",
    "        if i == (Layers - 1):\n",
    "            dim.append([1, neurons[i]])\n",
    "    dim = np.array(dim)\n",
    "    use_L2 = int(input(\"do you want to use L2 initialization: \"))\n",
    "    return Layers, dim, use_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ad5a42c-a1d7-410f-8788-1a611bb8bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adam_optimization(W, B, Vw, Vb, Sw, Sb, dW, dB, iteration, learning_rate, B1=0.9, B2=0.999, epsilon=1e-8):\n",
    "    for l in range(W.shape[0]):\n",
    "        Vw[l, 0] = B1 * Vw[l, 0] + (1 - B1) * dW[l, 0]\n",
    "        Vb[l, 0] = B1 * Vb[l, 0] + (1 - B1) * dB[l, 0]\n",
    "        Sw[l, 0] = B2 * Sw[l, 0] + (1 - B2) * (dW[l, 0] ** 2)\n",
    "        Sb[l, 0] = B2 * Sb[l, 0] + (1 - B2) * (dB[l, 0] ** 2)\n",
    "\n",
    "        Vw_corrected = Vw[l, 0] / (1 - B1 ** iteration)\n",
    "        Vb_corrected = Vb[l, 0] / (1 - B1 ** iteration)\n",
    "        Sw_corrected = Sw[l, 0] / (1 - B2 ** iteration)\n",
    "        Sb_corrected = Sb[l, 0] / (1 - B2 ** iteration)\n",
    "\n",
    "        W[l, 0] -= learning_rate * (Vw_corrected / (np.sqrt(Sw_corrected) + epsilon))\n",
    "        B[l, 0] -= learning_rate * (Vb_corrected / (np.sqrt(Sb_corrected) + epsilon))\n",
    "\n",
    "    return Vw, Vb, Sw, Sb, W, B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "14ad74ff-aea8-4018-acdf-571609fa31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_mini, Y_mini, X, Y, learning_rate = 2, num_itiration = 10001, decay_rate = 0.001):\n",
    "    Layers, dim, use_L2 = get_layer()\n",
    "    cost = []\n",
    "    W = HE_initialize(dim)\n",
    "    B = initialize_zero(dim)\n",
    "    Vw = np.empty_like(W)\n",
    "    Vb = np.empty_like(B)\n",
    "    Sw = np.empty_like(W)\n",
    "    Sb = np.empty_like(B)\n",
    "    for l in range(Vw.shape[0]):\n",
    "        Vw[l, 0] = np.zeros_like(W[l, 0])\n",
    "    for l in range(Vb.shape[0]):\n",
    "        Vb[l, 0] = np.zeros_like(B[l, 0])\n",
    "    for l in range(Sw.shape[0]):\n",
    "        Sw[l, 0] = np.zeros_like(W[l, 0])\n",
    "    for l in range(Sb.shape[0]):\n",
    "        Sb[l, 0] = np.zeros_like(B[l, 0])\n",
    "    for i in range(num_itiration):\n",
    "        current_lr = learning_rate / (1 + decay_rate * i)\n",
    "        for j in range(len(X_mini)):\n",
    "            A = forward_propagation(W, X_mini[j], B)\n",
    "            dW, dB = backward_propagation(W, B, A, Y_mini[j], use_L2)\n",
    "            vW, Vb, Sw, Sb, W, B = Adam_optimization(W, B, Vw, Vb, Sw, Sb, dW, dB, i * len(X_mini) + j + 1, current_lr)\n",
    "        if i >= 50:\n",
    "            A = forward_propagation(W, X, B)\n",
    "            cost.append(calculate_cost(Y, A[-1][0], use_L2))\n",
    "            if i%200 ==0 or i == num_itiration - 1:\n",
    "                print(cost[i -50])\n",
    "    plt.plot(range(num_itiration- 50), cost) \n",
    "    plt.show()\n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7efc8011-15a2-4a74-a791-c0f6932c368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_deep(X, Y, W, B):\n",
    "    count = 0\n",
    "    A = forward_propagation(W, X, B)\n",
    "    Z = perdiction(A[-1][0])\n",
    "    for i in range(Y.shape[1]):\n",
    "        if Z[0][i] == Y[0][i]:\n",
    "            count += 1\n",
    "    accuricy = count/Y.shape[1] * 100\n",
    "    return accuricy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5d59906c-3dea-41bf-9c20-53e8ba10b7e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input number of layers:  1\n",
      "input nerouns for 1th layer:  7\n",
      "do you want to use L2 initialization:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6464701420468375\n",
      "0.6460621296943831\n",
      "0.6457248820377386\n",
      "0.6454772844936667\n",
      "0.6452918621492044\n",
      "0.6451488735939968\n",
      "0.6450357135083027\n",
      "0.6449442149368717\n",
      "0.6448689015444118\n",
      "0.6448059731321744\n",
      "0.6447527127956387\n",
      "0.6447071287753902\n",
      "0.6446677297278584\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m W, B \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x_mini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y_mini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set_x_shuffled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set_y_shuffeled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m acc_test \u001b[38;5;241m=\u001b[39m test_deep(test_set_x, test_set_y, W, B)\n\u001b[1;32m      3\u001b[0m acc_train \u001b[38;5;241m=\u001b[39m test_deep(train_set_x, train_set_y, W, B)\n",
      "Cell \u001b[0;32mIn[95], line 25\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(X_mini, Y_mini, X, Y, learning_rate, num_itiration, decay_rate)\u001b[0m\n\u001b[1;32m     23\u001b[0m     vW, Vb, Sw, Sb, W, B \u001b[38;5;241m=\u001b[39m Adam_optimization(W, B, Vw, Vb, Sw, Sb, dW, dB, i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_mini) \u001b[38;5;241m+\u001b[39m j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, current_lr)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     cost\u001b[38;5;241m.\u001b[39mappend(calculate_cost(Y, A[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m], use_L2))\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m num_itiration \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36mforward_propagation\u001b[0;34m(W, X, B)\u001b[0m\n\u001b[1;32m      4\u001b[0m A[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(layers):\n\u001b[0;32m----> 6\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m B[l][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m!=\u001b[39m layers\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      8\u001b[0m         a \u001b[38;5;241m=\u001b[39m RELU(z)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W, B = model(train_x_mini, train_y_mini, train_set_x_shuffled, train_set_y_shuffeled)\n",
    "acc_test = test_deep(test_set_x, test_set_y, W, B)\n",
    "acc_train = test_deep(train_set_x, train_set_y, W, B)\n",
    "print(acc_train, \"\\n\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90471b53-f0d3-4d93-810f-bd9e99a712f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
